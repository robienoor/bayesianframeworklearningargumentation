{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05316901 0.05316901 0.07007042 0.05316901 0.05316901 0.05316901\n",
      " 0.05316901 0.05880282 0.07570423 0.05035211 0.09260563 0.07570423\n",
      " 0.09260563 0.05316901 0.05316901 0.05880282]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import sys \n",
    "import csv\n",
    "import time\n",
    "from scipy import stats\n",
    "sys.path.append('..')\n",
    "import math\n",
    "import pandas as pd\n",
    "from prior import prior\n",
    "from liklihood import liklihood\n",
    "from posterior import posterior\n",
    "import graph_image_generator\n",
    "import utilities\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalGraphs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_distribution_rating = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_G_2args = prior(['a'], ['c'])\n",
    "p_G_2args_prior_distribution =  p_G_2args.getDistribution(prior_distribution_rating)\n",
    "\n",
    "p_G_3args = prior(['a','b'], ['c'])\n",
    "p_G_3args_prior_distribution =  p_G_3args.getDistribution(prior_distribution_rating)\n",
    "\n",
    "p_G_3args_2 = prior(['a','d'], ['c'])\n",
    "p_G_3args_2_prior_distribution =  p_G_3args_2.getDistribution(prior_distribution_rating)\n",
    "\n",
    "p_G_4args = prior(['a','d','b'], ['c'])\n",
    "p_G_4args_prior_distribution =  p_G_4args.getDistribution(prior_distribution_rating)\n",
    "\n",
    "p_G_5args = prior(['a','d','b'], ['c','e'])\n",
    "p_G_5args_prior_distribution =  p_G_5args.getDistribution(prior_distribution_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_p_g = [p_G_2args, p_G_3args, p_G_3args_2, p_G_4args, p_G_5args]\n",
    "all_prior_distribs = [p_G_2args_prior_distribution, \n",
    "                     p_G_3args_prior_distribution,\n",
    "                     p_G_3args_2_prior_distribution,\n",
    "                     p_G_4args_prior_distribution,\n",
    "                     p_G_5args_prior_distribution]\n",
    "index_p_G_s = list(range(len(all_p_g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_attack_holds(pos_args, neg_args, always_true, graph):\n",
    "    \n",
    "    all_args = pos_args + neg_args\n",
    "    appropriate_graph = []\n",
    "    \n",
    "    for t in always_true:\n",
    "        \n",
    "        if t[0][0] not in all_args or t[0][1] not in all_args:\n",
    "            appropriate_graph.append(False)\n",
    "            continue\n",
    "            \n",
    "        attacker = all_args.index(t[0][0])\n",
    "        attacked = all_args.index(t[0][1])\n",
    "        \n",
    "        if len(t) == 1:\n",
    "            if graph[attacker, attacked] == 1 and graph[attacked, attacker] == 0:\n",
    "                appropriate_graph.append(True)\n",
    "            else:\n",
    "                appropriate_graph.append(False)\n",
    "            continue\n",
    "            \n",
    "        if len(t) == 2:\n",
    "            if graph[attacker, attacked] == 1 and graph[attacked, attacker] == 1:\n",
    "                appropriate_graph.append(True)\n",
    "            else:\n",
    "                appropriate_graph.append(False)\n",
    "            continue\n",
    "            \n",
    "    return all(appropriate_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,16):\n",
    "    print(i)\n",
    "    print(check_attack_holds(all_p_g[1].pos_args, all_p_g[1].neg_args, \n",
    "                       [[('a','c'),('c','a')],[('c', 'b'),('b','c')]], \n",
    "                       all_p_g[1].arg_matrices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateSyntheticObservations(target_no_observations, all_p_g, all_prior_distribs, degree_of_appearance, always_true):\n",
    "\n",
    "    observations = []\n",
    "    index_p_G_s = list(range(len(all_p_g)))\n",
    "\n",
    "    while len(observations) < target_no_observations:\n",
    "        choice = random.choice(index_p_G_s) # choose an index from the list, index corresponds to one of the graph spaces\n",
    "        chosen_prior = all_prior_distribs[choice] # store the prior for the graph space\n",
    "\n",
    "\n",
    "        possible_graphs = []\n",
    "        possible_graphs_probabilities = []\n",
    "\n",
    "        appear_draw = random.uniform(0, 1)\n",
    "        if appear_draw <= degree_of_appearance:\n",
    "            for graph_no, graph in enumerate((all_p_g[choice]).arg_matrices):\n",
    "                result = check_attack_holds(all_p_g[choice].pos_args, all_p_g[choice].neg_args, always_true, graph)\n",
    "                if result:            \n",
    "                    possible_graphs.append(graph)\n",
    "                    possible_graphs_probabilities.append(chosen_prior[graph_no])\n",
    "\n",
    "            if len(possible_graphs) ==0:\n",
    "                continue\n",
    "            possible_graphs_probabilities = possible_graphs_probabilities / np.sum(possible_graphs_probabilities)\n",
    "\n",
    "        else:\n",
    "            possible_graphs = (all_p_g[choice]).arg_matrices\n",
    "            possible_graphs_probabilities = chosen_prior\n",
    "\n",
    "\n",
    "        indices = list(range(len(possible_graphs_probabilities)))\n",
    "        custm = stats.rv_discrete(name='custm', values=(indices, possible_graphs_probabilities))\n",
    "        chosen_graph = custm.rvs(size=1)[0]\n",
    "\n",
    "        observation = {}\n",
    "        observation['pos_args'] = all_p_g[choice].pos_args\n",
    "        observation['neg_args'] = all_p_g[choice].neg_args\n",
    "        observation['attacks'] = utilities.convertArgMtrxToAttacks(observation['pos_args'], \n",
    "                                                                   observation['neg_args'],\n",
    "                                                                  possible_graphs[chosen_graph])\n",
    "\n",
    "        observation['rating'] = 10\n",
    "\n",
    "        observations.append(observation)\n",
    "        \n",
    "\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runSingleSimulation(always_true, noObservations, appearance):\n",
    "\n",
    "    graph_probabilities = []\n",
    "    for i in range(5):\n",
    "        observations = generateSyntheticObservations(noObservations, all_p_g, all_prior_distribs, appearance, always_true)\n",
    "        target_distribution = {}\n",
    "        target_distribution['pos_args'] = ['a','b','d']\n",
    "        target_distribution['neg_args'] = ['c','e']\n",
    "        target_distribution['rating'] = 10\n",
    "\n",
    "        p_G = prior(target_distribution['pos_args'], target_distribution['neg_args'])\n",
    "\n",
    "        # generate the prior distribution\n",
    "        target_prior_distribution = p_G.getDistribution(target_distribution['rating'])\n",
    "\n",
    "        p_G.rating = 10\n",
    "        all_updates_distribution = []\n",
    "\n",
    "        current_prior = target_prior_distribution\n",
    "        \n",
    "        for synthetic_observation in observations:\n",
    "            p_G_T = liklihood(p_G, synthetic_observation)\n",
    "            print(p_G_T.observation_type)\n",
    "            s = time.time()\n",
    "            liklihood_distribution = p_G_T.buildLiklihoodDistribution()\n",
    "            print(time.time() - s)\n",
    "            \n",
    "            s = time.time()\n",
    "            p_T_G = posterior(current_prior, liklihood_distribution)\n",
    "            posterior_distribution = p_T_G.buildPosteriorDistribution()\n",
    "            all_updates_distribution.append(posterior_distribution)\n",
    "            print(time.time() - s)\n",
    "            current_prior = posterior_distribution\n",
    "        print('---')\n",
    "\n",
    "        graph_probabilities.append(current_prior[0])\n",
    "\n",
    "    return graph_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_probabilities_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar\n",
      "1.562695026397705\n",
      "0.00034999847412109375\n",
      "matching\n",
      "0.001505136489868164\n",
      "2.4080276489257812e-05\n",
      "similar\n",
      "1.4811770915985107\n",
      "3.409385681152344e-05\n",
      "similar\n",
      "1.6003739833831787\n",
      "0.00026106834411621094\n",
      "similar\n",
      "1.5561189651489258\n",
      "3.0994415283203125e-05\n",
      "similar\n",
      "1.560595989227295\n",
      "3.409385681152344e-05\n",
      "similar\n",
      "1.5355119705200195\n",
      "4.76837158203125e-05\n",
      "matching\n",
      "0.002849102020263672\n",
      "3.695487976074219e-05\n",
      "similar\n",
      "1.644423246383667\n",
      "3.0994415283203125e-05\n",
      "similar\n",
      "1.6745188236236572\n",
      "2.9802322387695312e-05\n",
      "matching\n",
      "0.0004448890686035156\n",
      "3.504753112792969e-05\n",
      "similar\n",
      "1.539801836013794\n",
      "3.1948089599609375e-05\n",
      "matching\n",
      "0.003144979476928711\n",
      "0.0001430511474609375\n",
      "matching\n",
      "0.001977205276489258\n",
      "3.600120544433594e-05\n",
      "similar\n",
      "1.644266128540039\n",
      "0.00020599365234375\n",
      "similar\n",
      "1.5417168140411377\n",
      "3.314018249511719e-05\n",
      "similar\n",
      "1.6169359683990479\n",
      "3.3855438232421875e-05\n",
      "similar\n",
      "1.502234935760498\n",
      "0.00028705596923828125\n",
      "similar\n",
      "1.60280442237854\n",
      "3.504753112792969e-05\n",
      "similar\n",
      "1.5458953380584717\n",
      "3.3855438232421875e-05\n",
      "similar\n",
      "1.480983018875122\n",
      "3.719329833984375e-05\n",
      "similar\n",
      "1.5653419494628906\n",
      "3.314018249511719e-05\n",
      "matching\n",
      "0.0006649494171142578\n",
      "2.288818359375e-05\n",
      "similar\n",
      "1.55610990524292\n",
      "3.1948089599609375e-05\n",
      "matching\n",
      "0.0016031265258789062\n",
      "3.600120544433594e-05\n",
      "---\n",
      "similar\n",
      "1.5915021896362305\n",
      "0.0003552436828613281\n",
      "matching\n",
      "0.00043487548828125\n",
      "2.6941299438476562e-05\n",
      "matching\n",
      "9.822845458984375e-05\n",
      "2.9325485229492188e-05\n",
      "matching\n",
      "7.081031799316406e-05\n",
      "2.3126602172851562e-05\n",
      "similar\n",
      "1.5669238567352295\n",
      "0.0001270771026611328\n",
      "similar\n",
      "1.5645811557769775\n",
      "3.695487976074219e-05\n",
      "similar\n",
      "1.532102108001709\n",
      "3.2901763916015625e-05\n",
      "similar\n",
      "1.5525999069213867\n",
      "3.314018249511719e-05\n",
      "similar\n",
      "1.5639140605926514\n",
      "0.0001361370086669922\n",
      "similar\n",
      "1.510810136795044\n",
      "0.00024580955505371094\n",
      "similar\n",
      "1.8886399269104004\n",
      "0.00024199485778808594\n",
      "similar\n",
      "1.9777171611785889\n",
      "0.00019502639770507812\n",
      "matching\n",
      "0.0037789344787597656\n",
      "0.00016880035400390625\n",
      "similar\n",
      "1.565290927886963\n",
      "4.673004150390625e-05\n",
      "similar\n",
      "1.726128101348877\n",
      "3.1948089599609375e-05\n",
      "similar\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-15650b53a411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnoObservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mappearance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgraph_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunSingleSimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoObservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappearance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-450057b07967>\u001b[0m in \u001b[0;36mrunSingleSimulation\u001b[0;34m(always_true, noObservations, appearance)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_G_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mliklihood_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_G_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildLiklihoodDistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kawsarnoor/Desktop/PhD Work/code/bayesianframeworklearning/liklihood.py\u001b[0m in \u001b[0;36mbuildLiklihoodDistribution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliklihood_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildMatchingLiklihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_distribution_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliklihood_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildSimilarLiklihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_distribution_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliklihood_distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kawsarnoor/Desktop/PhD Work/code/bayesianframeworklearning/liklihood.py\u001b[0m in \u001b[0;36mbuildSimilarLiklihood\u001b[0;34m(current_prior, observation_data, uniform_distribution_value)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_prior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_matrices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mdiffs_sims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_similar_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_conflicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mdiffs_grounded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroundedDiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mgraph_space_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mdiffs_sims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffs_sims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kawsarnoor/Desktop/PhD Work/code/bayesianframeworklearning/liklihood.py\u001b[0m in \u001b[0;36mgroundedDiff\u001b[0;34m(observation_data, graph_martix, observation_args, graph_space_args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgroundedDiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_martix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_space_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mgraph_grounded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateGroundedExtension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_martix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mobservation_grounded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateGroundedExtension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'argMtx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mgraph_grounded_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgraph_space_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph_grounded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kawsarnoor/Desktop/PhD Work/code/bayesianframeworklearning/utilities.py\u001b[0m in \u001b[0;36mcalculateGroundedExtension\u001b[0;34m(argMtx)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0margsDelete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minArgs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutArgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0margMtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margMtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margsDelete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0margMtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margMtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margsDelete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0margTypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margTypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margsDelete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Users/kawsarnoor/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   4402\u001b[0m                 \"error in the future\", DeprecationWarning, stacklevel=3)\n\u001b[1;32m   4403\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4404\u001b[0;31m         \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;31m# Test if there are out of bound indices, this is deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kawsarnoor/anaconda/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, order)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \"\"\"\n\u001b[1;32m    214\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "always_true = [[('a', 'c')], [('b', 'c')], [('d', 'c')],[('a','e')],[('b','e')],[('d','e')]]\n",
    "noObservations = 25\n",
    "appearance = 0.25\n",
    "graph_probabilities = runSingleSimulation(always_true, noObservations, appearance)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_probabilities_dict[float(appearance*10)] = graph_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = sorted(graph_probabilities_dict[float(appearance*10)])  #sorted\n",
    "fit = stats.norm.pdf(h, np.mean(h), np.std(h))  #this is a fitting indeed\n",
    "\n",
    "plt.plot(h,fit)\n",
    "      #use this to draw histogram of your data\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.xlabel('P(G|T)')\n",
    "\n",
    "for key, item in graph_probabilities_dict.items():\n",
    "    if key == 0:\n",
    "        continue \n",
    "\n",
    "    h = sorted(item)\n",
    "\n",
    "    fit = stats.norm.pdf(h, np.mean(h), np.std(h))  #this is a fitting indeed\n",
    "\n",
    "    noise_level = round(1 - key/10, 2)\n",
    "    \n",
    "    plt.plot(h,fit, label='noise='+ str(noise_level))\n",
    "      #use this to draw histogram of your data\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save last figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig.savefig('figures/ultimatesimulation_noise'+ str(noise_level) +'_noobservations' + str(noObservations) +'_150trials.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save agreeable graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalGraph = {\n",
    "    'target_distribution': target_distribution,\n",
    "    'always_true': always_true,\n",
    "    'noObservations': noObservations,\n",
    "    'appearance': appearance,\n",
    "    'graph_probabilities_dict': graph_probabilities_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalGraphs.append(finalGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalGraphsDF = pd.DataFrame(finalGraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalGraphsDF.to_json('final_distributions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalGraphsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Work through means of graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runTrialForGraph():\n",
    "    always_true = [[('c','a')],[('c', 'b')]]\n",
    "    \n",
    "    for noObservations in [5,10,15,20,25]:\n",
    "        graph_probabilities_dict = {}\n",
    "\n",
    "        \n",
    "        for appearance in [0.25,0.5,0.75]:\n",
    "            \n",
    "            graph_probabilities = runSingleSimulation(always_true, noObservations, appearance)\n",
    "            graph_probabilities_dict[float(appearance*10)] = graph_probabilities\n",
    "     \n",
    "        finalGraph = {\n",
    "            'target_distribution': target_distribution,\n",
    "            'always_true': always_true,\n",
    "            'noObservations': noObservations,\n",
    "            'graph_probabilities_dict': graph_probabilities_dict\n",
    "        }\n",
    "        \n",
    "        finalGraphs.append(finalGraph)\n",
    "        \n",
    "        print('completed ', noObservations, 'with ', always_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runTrialForGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalGraphsDF = pd.DataFrame(finalGraphs)\n",
    "finalGraphsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertIntoMeanGraph(always_true, appearance):\n",
    "    finalGraphsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in finalGraphsDF.iloc[20:25].itertuples():\n",
    "    print(np.mean(i.graph_probabilities_dict[7.5]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "three_arg_sampled_graphs = [(0,5,0),\n",
    "                           (5,10,1598),\n",
    "                           (10,15,2808),\n",
    "                           (15,20,3083),\n",
    "                           (20,25,4095)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mean_probs = []\n",
    "# Compute the probabilitiy means\n",
    "\n",
    "noiselevel = 5.0\n",
    "\n",
    "for sampled_graph in three_arg_sampled_graphs:\n",
    "    \n",
    "    mean_probs = []\n",
    "    for i in finalGraphsDF.iloc[sampled_graph[0]:sampled_graph[1]].itertuples():\n",
    "        mean_probs.append(np.mean(i.graph_probabilities_dict[noiselevel]))\n",
    "        \n",
    "    all_mean_probs.append(mean_probs)\n",
    "    \n",
    "# Put the prior at the top of each list for each graph for plotting purposes\n",
    "\n",
    "for idx, mean_prob in enumerate(all_mean_probs):\n",
    "    mean_prob.insert(0, p_G_3args_prior_distribution[three_arg_sampled_graphs[idx][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for amp in all_mean_probs:\n",
    "    \n",
    "    plt.plot([0,5,10,15,20,25],amp)\n",
    "\n",
    "plt.ylabel('P(G|T)')\n",
    "plt.xlabel('No. of Observations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig('figures/mean_simulations_3args_noise' + str(noiselevel/10) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the average of the points as a single line with a band around it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem, t\n",
    "from scipy import mean\n",
    "confidence = 0.95\n",
    "\n",
    "smooth_path = []\n",
    "overline = []\n",
    "underline = []\n",
    "path_deviation = []\n",
    "for all_mean in np.array(all_mean_probs).T:\n",
    "    n = len(all_mean)\n",
    "    m = mean(all_mean)\n",
    "    std_err = sem(all_mean)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    \n",
    "    smooth_path.append(m)\n",
    "    path_deviation.append(h)\n",
    "    overline.append(m+h)\n",
    "    underline.append(m-h)\n",
    "\n",
    "path_deviation = list(range(0,len(path_deviation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([0,5,10,15,20,25],smooth_path) #mean curve.\n",
    "plt.fill_between([0,5,10,15,20,25], underline, overline, color='b', alpha=.1)\n",
    "plt.ylabel('P(G|T)')\n",
    "plt.xlabel('No. of Observations')\n",
    "plt.show()\n",
    "fig.savefig('figures/confidence_interval_3arg_noise_'+str(noiselevel/10)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some example data\n",
    "x= np.linspace(0.1, 9.9, 20)\n",
    "y = 3.0 * x\n",
    "#some confidence interval\n",
    "ci = 1.96 * np.std(y)/np.mean(y)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y)\n",
    "ax.fill_between(x, (y-ci), (y+ci), color='b', alpha=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y+ci).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([5,10,15,20,25],smooth_path) #mean curve.\n",
    "plt.fill_between([5,10,15,20,25], underline, overline, color='b', alpha=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(overline).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
